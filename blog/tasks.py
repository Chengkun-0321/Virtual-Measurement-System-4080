# blog/tasks.py
import os
import logging
import subprocess
from asgiref.sync import async_to_sync
from celery import shared_task
from channels.layers import get_channel_layer

import pandas as pd
import numpy as np
from tensorflow.keras.models import load_model

logger = logging.getLogger(__name__)

@shared_task(bind=True)
def train_model(self, model, dataset, epochs, batch_size, learning_rate, validation_freq):
    """
    Celery ä»»å‹™ï¼šå‘¼å« mamba ç’°å¢ƒçš„ train_code.py åŸ·è¡Œæ¨¡å‹è¨“ç·´
    """
    if model == "Mamba":
        model_dir = os.path.expanduser("~/Virtual_Measurement_System_model/Model_code/")
        venv_dir = "mamba"
        py_file = "train_code.py"
    else:
        return {"status": "error", "logs": ["âŒ å°šæœªæ”¯æ´è©²æ¨¡å‹æ¶æ§‹"]}

    cmd = (
        f"cd {model_dir} && "
        f"source ~/anaconda3/etc/profile.d/conda.sh && "
        f"conda activate {venv_dir} && "
        f"python {py_file} "
        f"--train_x './process_data_Splitting/training_data/{dataset}/cnn-2d_2020-09-09_11-45-24_x.npy' "
        f"--train_y './process_data_Splitting/training_data/{dataset}/cnn-2d_2020-09-09_11-45-24_y.npy' "
        f"--valid_x './process_data_Splitting/validation_data/{dataset}/cnn-2d_2020-09-09_11-45-24_x.npy' "
        f"--valid_y './process_data_Splitting/validation_data/{dataset}/cnn-2d_2020-09-09_11-45-24_y.npy' "
        f"--epochs {epochs} --batch_size {batch_size} --lr {learning_rate} --validation_freq {validation_freq}"
    )

    process = subprocess.Popen(
        cmd, shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        executable="/bin/bash"
    )

    # æº–å‚™ WebSocket channel layer
    channel_layer = get_channel_layer()

    logs = []
    for line in iter(process.stdout.readline, b""):
        log_line = line.decode().strip()
        logs.append(log_line)

        # å³æ™‚æ¨é€åˆ° WebSocket (training_group æ˜¯ä½ åœ¨ consumer è£¡è¨‚çš„ group name)
        async_to_sync(channel_layer.group_send)(
            "training_group",
            {
                "type": "training.log",   # æœƒå‘¼å« consumer è£¡çš„ training_log()
                "message": log_line
            }
        )
        logger.info(f"å°‡è¨Šæ¯é€åˆ°å‰ç«¯ TRAIN/: {log_line}")

    process.wait()
    err = process.stderr.read().decode()
    if err:
        logs.append("âŒ Error: " + err)
        async_to_sync(channel_layer.group_send)(
            "training_group",
            {"type": "training.log", "message": "âŒ Error: " + err}
        )

    # è¨“ç·´å®Œæˆé€šçŸ¥
    async_to_sync(channel_layer.group_send)(
        "training_group",
        {"type": "training.log", "message": "__FINISHED__"}
    )

    return {"status": "done"}

@shared_task(bind=True)
def test_model(self, model, dataset, checkpoint, mean, upper, lower):
    """
    Celery ä»»å‹™ï¼šå‘¼å« mamba ç’°å¢ƒçš„ test_code.py åŸ·è¡Œæ¨¡å‹è¨“ç·´
    """
    if model == "Mamba":
        model_dir = os.path.expanduser("~/Virtual_Measurement_System_model/Model_code/")
        venv_dir = "mamba"
        py_file = "test_code.py"
    else:
        return {"status": "error", "logs": ["âŒ å°šæœªæ”¯æ´è©²æ¨¡å‹æ¶æ§‹"]}

    cmd = (
        f"cd {model_dir} && "
        f"source ~/anaconda3/etc/profile.d/conda.sh && "
        f"conda activate {venv_dir} && "
        f"python -u {py_file} "
        f"--test_x_path './process_data_Splitting/testing_data/{dataset}/cnn-2d_2020-09-09_11-45-24_x.npy' "
        f"--test_y_path './process_data_Splitting/testing_data/{dataset}/cnn-2d_2020-09-09_11-45-24_y.npy' "
        f"--checkpoint_path checkpoints/{checkpoint}.h5 "
        f"--mean '{mean}' "
        f"--boundary_upper '{upper}' "
        f"--boundary_lower '{lower}'"
    )

    process = subprocess.Popen(
        cmd, shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        executable="/bin/bash"
    )

    # æº–å‚™ WebSocket channel layer
    channel_layer = get_channel_layer()

    logs = []
    for line in iter(process.stdout.readline, b""):
        log_line = line.decode().strip()
        logs.append(log_line)

        # å³æ™‚æ¨é€åˆ° WebSocket (training_group æ˜¯ä½ åœ¨ consumer è£¡è¨‚çš„ group name)
        async_to_sync(channel_layer.group_send)(
            "testing_group",
            {
                "type": "testing.log",   # æœƒå‘¼å« consumer è£¡çš„ testing_log()
                "message": log_line
            }
        )
        logger.info(f"å°‡è¨Šæ¯é€åˆ°å‰ç«¯ TEST/: {log_line}")

    process.wait()
    err = process.stderr.read().decode()
    if err:
        logs.append("âŒ Error: " + err)
        async_to_sync(channel_layer.group_send)(
            "testing_group",
            {"type": "testing.log", "message": "âŒ Error: " + err}
        )

    # è¨“ç·´å®Œæˆé€šçŸ¥
    async_to_sync(channel_layer.group_send)(
        "testing_group",
        {"type": "testing.log", "message": "__FINISHED__"}
    )

    return {"status": "done"}

@shared_task(bind=True)
def predict_model(self, model_name, indices, data_json):
    """
    Celery ä»»å‹™ï¼šå‘¼å«æ¨¡å‹åšé æ¸¬
    """
    channel_layer = get_channel_layer()
    logs = []
    try:
        # é‚„åŸ DataFrame
        selected_df = pd.read_json(data_json, orient="split")

        # æ¨¡å‹è·¯å¾‘
        model_dir = os.path.expanduser("~/Virtual_Measurement_System_model/Model_code/checkpoints")
        model_path = os.path.join(model_dir, model_name + ".h5")

        # è¼‰å…¥æ¨¡å‹
        msg = f"ğŸ“‚ è¼‰å…¥æ¨¡å‹ {model_name}.h5"
        async_to_sync(channel_layer.group_send)(
            "deploying_group",
            {"type": "deploying.log", "message": msg}
        )
        logger.info(msg)
        model = load_model(model_path, compile=False)

        # é æ¸¬è³‡æ–™
        data_np = selected_df.to_numpy().reshape(-1, 9, 9, 1).astype(np.float32)
        msg = f"â–¶ï¸ é–‹å§‹é æ¸¬ï¼Œå…± {data_np.shape[0]} ç­†è³‡æ–™"
        async_to_sync(channel_layer.group_send)(
            "deploying_group",
            {"type": "deploying.log", "message": msg}
        )
        logger.info(msg)

        predictions = model.predict(data_np, verbose=1)

        for i, value in enumerate(predictions.flatten().round(3).tolist()):
            log_line = f"[{i+1}] {value}"
            logs.append(log_line)
            async_to_sync(channel_layer.group_send)(
                "deploying_group",
                {"type": "deploying.log", "message": log_line}
            )
            logger.info(f"å°‡è¨Šæ¯é€åˆ°å‰ç«¯ DEPLOY/:{log_line}")
        
        pred_result = predictions.flatten().round(3).tolist()

        # é æ¸¬å®Œæˆé€šçŸ¥
        async_to_sync(channel_layer.group_send)(
            "deploying_group",
            {"type": "deploying.log", "message": f"âœ… å®Œæˆé æ¸¬ï¼Œå…± {len(pred_result)} ç­†"}
        )

            # å‚³é€é æ¸¬çµæœ
        async_to_sync(channel_layer.group_send)(
            "deploying_group",
            {"type": "deploying.log", "message": f"çµæœ: {pred_result}"}
        )

        return {"status": "success", "predictions": pred_result}

    except Exception as e:
        async_to_sync(channel_layer.group_send)(
            "deploying_group",
            {"type": "deploying.log", "message": f"âŒ Error: {str(e)}"}
        )
        return {"status": "error", "message": str(e)}