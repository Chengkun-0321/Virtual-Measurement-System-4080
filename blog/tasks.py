# blog/tasks.py
import json
import os
import logging
import subprocess
from asgiref.sync import async_to_sync
from celery import shared_task
from channels.layers import get_channel_layer

import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)

@shared_task(bind=True)
def train_model(self, model, dataset, epochs, batch_size, learning_rate, validation_freq):
    """
    Celery ä»»å‹™ï¼šå‘¼å« mamba ç’°å¢ƒçš„ train_code.py åŸ·è¡Œæ¨¡å‹è¨“ç·´
    """
    if model == "Mamba":
        model_dir = os.path.expanduser("~/Virtual_Measurement_System_model/Model_code/")
        venv_dir = "mamba"
        py_file = "train_code.py"
    else:
        return {"status": "error", "logs": ["âŒ å°šæœªæ”¯æ´è©²æ¨¡å‹æ¶æ§‹"]}

    cmd = (
        f"cd {model_dir} && "
        f"source ~/anaconda3/etc/profile.d/conda.sh && "
        f"conda activate {venv_dir} && "
        f"python {py_file} "
        f"--train_x './Dataset/{dataset}/Train/x.npy' "
        f"--train_y './Dataset/{dataset}/Train/y.npy' "
        f"--valid_x './Dataset/{dataset}/Validation/x.npy' "
        f"--valid_y './Dataset/{dataset}/Validation/y.npy' "
        f"--epochs {epochs} --batch_size {batch_size} --lr {learning_rate} --validation_freq {validation_freq}"
    )

    process = subprocess.Popen(
        cmd, shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        executable="/bin/bash"
    )

    # æº–å‚™ WebSocket channel layer
    channel_layer = get_channel_layer()

    logs = []
    for line in iter(process.stdout.readline, b""):
        log_line = line.decode().strip()
        logs.append(log_line)

        # å³æ™‚æ¨é€åˆ° WebSocket (training_group æ˜¯ä½ åœ¨ consumer è£¡è¨‚çš„ group name)
        async_to_sync(channel_layer.group_send)(
            "training_group",
            {
                "type": "training.log",   # æœƒå‘¼å« consumer è£¡çš„ training_log()
                "message": log_line
            }
        )
        logger.info(f"å°‡è¨Šæ¯é€é redis é€åˆ°å‰ç«¯ TRAIN/: {log_line}")

    process.wait()
    err = process.stderr.read().decode()
    if err:
        logs.append("âŒ Error: " + err)
        async_to_sync(channel_layer.group_send)(
            "training_group",
            {"type": "training.log", "message": "âŒ Error: " + err}
        )

    # è¨“ç·´å®Œæˆé€šçŸ¥
    async_to_sync(channel_layer.group_send)(
        "training_group",
        {"type": "training.log", "message": "__FINISHED__"}
    )

    return {"status": "done"}

@shared_task(bind=True)
def test_model(self, model, dataset, checkpoint, mean, upper, lower):
    """
    Celery ä»»å‹™ï¼šå‘¼å« mamba ç’°å¢ƒçš„ test_code.py åŸ·è¡Œæ¨¡å‹è¨“ç·´
    """
    if model == "Mamba":
        model_dir = os.path.expanduser("~/Virtual_Measurement_System_model/Model_code/")
        venv_dir = "mamba"
        py_file = "test_code.py"
    else:
        return {"status": "error", "logs": ["âŒ å°šæœªæ”¯æ´è©²æ¨¡å‹æ¶æ§‹"]}

    cmd = (
        f"cd {model_dir} && "
        f"source ~/anaconda3/etc/profile.d/conda.sh && "
        f"conda activate {venv_dir} && "
        f"python -u {py_file} "
        f"--test_x_path './Dataset/{dataset}/Test/x.npy' "
        f"--test_y_path './Dataset/{dataset}/Test/y.npy' "
        f"--checkpoint_path checkpoints/{checkpoint}.h5 "
        f"--mean '{mean}' "
        f"--boundary_upper '{upper}' "
        f"--boundary_lower '{lower}'"
    )

    process = subprocess.Popen(
        cmd, shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        executable="/bin/bash"
    )

    # æº–å‚™ WebSocket channel layer
    channel_layer = get_channel_layer()

    logs = []
    for line in iter(process.stdout.readline, b""):
        log_line = line.decode().strip()
        logs.append(log_line)

        # å³æ™‚æ¨é€åˆ° WebSocket (training_group æ˜¯ä½ åœ¨ consumer è£¡è¨‚çš„ group name)
        async_to_sync(channel_layer.group_send)(
            "testing_group",
            {
                "type": "testing.log",   # æœƒå‘¼å« consumer è£¡çš„ testing_log()
                "message": log_line
            }
        )
        logger.info(f"å°‡è¨Šæ¯é€é redis é€åˆ°å‰ç«¯ TEST/: {log_line}")

    process.wait()
    err = process.stderr.read().decode()
    if err:
        logs.append("âŒ Error: " + err)
        async_to_sync(channel_layer.group_send)(
            "testing_group",
            {"type": "testing.log", "message": "âŒ Error: " + err}
        )

    # è¨“ç·´å®Œæˆé€šçŸ¥
    async_to_sync(channel_layer.group_send)(
        "testing_group",
        {"type": "testing.log", "message": "__FINISHED__"}
    )

    return {"status": "done"}

@shared_task(bind=True)
def predict_model(self, model_name, indices, data_json):
    """
    Celery ä»»å‹™ï¼šå‘¼å« mamba ç’°å¢ƒçš„ predict_code.py åšé æ¸¬
    """
    # 1. WebSocket ç¾¤çµ„ (å°æ‡‰å‰ç«¯ DEPLOY)
    channel_layer = get_channel_layer()

    # 2. æª”æ¡ˆèˆ‡ç’°å¢ƒè¨­å®š
    model_dir = os.path.expanduser("~/Virtual_Measurement_System_model/Model_code/")
    venv_dir = "mamba"
    py_file = "predict_code.py"
    data_path = os.path.join(model_dir, "predict.json")

    # 3. å„²å­˜ data_json åˆ° predict.jsonï¼ˆéœ€è½‰æˆ dict æ‰èƒ½æ­£ç¢º dumpï¼‰
    print(f"ğŸ‘‰ å¯«å…¥ JSON åˆ°: {data_path}")
    if isinstance(data_json, str):
        data_json = json.loads(data_json)

    with open(data_path, "w") as f:
        json.dump(data_json, f)

    # 4. å»ºç«‹åŸ·è¡ŒæŒ‡ä»¤ï¼ˆä¸é˜»å¡ Djangoï¼‰
    cmd = (
        f"cd {model_dir} && "
        f"source ~/anaconda3/etc/profile.d/conda.sh && "
        f"conda activate {venv_dir} && "
        f"python -u {py_file} "
        f"--model {model_name} "      # é€™è£¡ model_name ä¸ç”¨åŠ  .h5
    )
    print(f"ğŸš€ åŸ·è¡ŒæŒ‡ä»¤ï¼š{cmd}")

    process = subprocess.Popen(
        cmd, shell=True,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        executable="/bin/bash"
    )

    # 5. å³æ™‚è®€å– stdout
    logs = []
    predictions = []
    for line in iter(process.stdout.readline, b""):
        log_line = line.decode().strip()
        logs.append(log_line)

        # å³æ™‚å‚³çµ¦å‰ç«¯
        async_to_sync(channel_layer.group_send)(
            "deploying_group",          # âœ… å°æ‡‰å‰ç«¯ /ws/DEPLOY/
            {
                "type": "deploying.log",
                "message": log_line
            }
        )

        # å¦‚æœæŠ“åˆ° RESULT:[...]
        if log_line.startswith("RESULT:"):
            try:
                predictions = eval(log_line.replace("RESULT:", "").strip())
            except:
                predictions = []

    # 6. å¦‚æœ stderr æœ‰éŒ¯èª¤ä¹Ÿæ¨çµ¦å‰ç«¯
    err = process.stderr.read().decode()
    if err:
        async_to_sync(channel_layer.group_send)(
            "deploying_group",
            {"type": "deploying.log", "message": "âŒ Error: " + err}
        )

    # 7. é€šçŸ¥å®Œæˆ
    async_to_sync(channel_layer.group_send)(
        "deploying_group",
        {"type": "deploying.log", "message": "__FINISHED__"}
    )

    return {"status": "done", "predictions": predictions}